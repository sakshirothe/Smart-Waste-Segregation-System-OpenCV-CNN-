# Smart-Waste-Segregation-System-OpenCV-CNN-
ğŸ—‘ï¸ Smart Waste Segregation System using OpenCV &amp; CNN  This project implements an AI-powered waste classification system capable of identifying four waste categories â€” Organic, Plastic, Paper, and Metal â€” in real time. The system uses a MobileNetV2-based Convolutional Neural Network (CNN) along with OpenCV to perform live detection using a webcam.

ğŸš€ Features

Real-time waste detection using webcam

Trained MobileNetV2 model for accurate classification

Organized dataset pipeline with data augmentation

High accuracy (~94% validation accuracy)

Automatic bounding box + label display

Lightweight model suitable for edge devices

ğŸ§  Tech Stack

Python

TensorFlow / Keras

OpenCV

NumPy

Pillow

Matplotlib

ğŸ“‚ Project Structure
Smart Waste/
â”‚
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ metal/
â”‚   â”œâ”€â”€ organic/
â”‚   â”œâ”€â”€ paper/
â”‚   â””â”€â”€ plastic/
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ waste_mobilenet.h5
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ prepare_dataset.py
â”‚   â”œâ”€â”€ train_mobilenet.py
â”‚   â””â”€â”€ realtime_detect.py
â”‚
â””â”€â”€ README.md

ğŸ“ How It Works

Dataset Preparation
Images are organized into categories and preprocessed for training.

Model Training
MobileNetV2 is used as the base model with fine-tuned layers.
The final model achieves high accuracy on the validation dataset.

Real-Time Detection
The trained model is loaded and used to classify frames captured from the webcam.

â–¶ï¸ Running the Project
1. Train the Model
python src/train_mobilenet.py


Model will be saved to models/waste_mobilenet.h5.

2. Run Real-Time Detection
python src/realtime_detect.py

ğŸ“¸ Output Example

Webcam feed with label overlay

Class: Organic / Metal / Paper / Plastic

Confidence score

ğŸ“š Applications

Smart waste bins

Recycling plants

Automated waste segregation

IoT-based environmental solutions

ğŸ›‘ README for Project 2 â€” Driver Drowsiness Detection System (OpenCV + dlib)
ğŸš— Driver Drowsiness Detection using Eye Aspect Ratio (EAR)

This project detects driver drowsiness in real-time using facial landmarks and Eye Aspect Ratio (EAR) measurement. When the driver closes their eyes for more than 4 seconds, an alarm automatically plays in the background.
If the driver's eyes remain open for more than 5 seconds, the alarm stops.

âœ¨ Features

Real-time eye detection using webcam

Eye aspect ratioâ€“based drowsiness monitoring

Background alarm audio (non-blocking)

Auto-start alarm when eyes closed for >4 sec

Auto-stop alarm when eyes open for >5 sec

Fast and lightweight

ğŸ§  Tech Stack

Python

OpenCV

dlib

Pygame (for audio playback)

NumPy

ğŸ“‚ Project Structure
DrowsinessDetection/
â”‚
â”œâ”€â”€ alarm.mp3
â”œâ”€â”€ shape_predictor_68_face_landmarks.dat
â”œâ”€â”€ drowsy_detect.py
â””â”€â”€ README.md

ğŸ”§ How It Works

dlib landmark detector finds the eyes

EAR value is calculated for left & right eye

If EAR < threshold for 4 seconds â†’ Alarm ON

If EAR > threshold for 5 seconds â†’ Alarm OFF

Alarm audio is played in background (non-blocking)

â–¶ï¸ Running the Project
python drowsy_detect.py


Press Q to quit.

ğŸ“¸ Output

Live webcam feed with:.

Eye boundary tracking

Real-time EAR value

Alerts for "Eyes Closed" & "Drowsiness Detected"
